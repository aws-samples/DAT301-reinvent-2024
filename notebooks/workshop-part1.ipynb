{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building AI-Powered Semantic Product Search with pgvector and Amazon Bedrock - Part 1\n",
    "### Setup, Data Loading, and Vector Generation\n",
    "\n",
    "---\n",
    "\n",
    "## Contents\n",
    "\n",
    "1. [Background](#Background)\n",
    "2. [Architecture](#Architecture)\n",
    "3. [Setup](#Setup)\n",
    "4. [Load Product Data](#Load-Product-Data)\n",
    "5. [Generate Embeddings](#Generate-Embeddings)\n",
    "6. [Store in PostgreSQL](#Store-in-PostgreSQL)\n",
    "\n",
    "## Background\n",
    "\n",
    "This workshop demonstrates how to build a semantic product search system using vector embeddings. Key components:\n",
    "\n",
    "- **Vector Embeddings**: Using Amazon Titan Embeddings to convert product descriptions into numerical vectors that capture semantic meaning\n",
    "- **Vector Storage**: Using pgvector extension in PostgreSQL to efficiently store and search these vectors\n",
    "- **Semantic Search**: Finding similar products by comparing vector distances\n",
    "\n",
    "## Architecture\n",
    "\n",
    "1. Product descriptions are converted to embeddings using Amazon Bedrock\n",
    "2. Embeddings are stored in PostgreSQL using pgvector extension\n",
    "3. Search queries are converted to embeddings and compared using vector similarity\n",
    "4. Most similar products are returned based on vector distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's install the required Python packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install all the required prerequiste libraries\n",
    "%pip install setuptools==65.5.0\n",
    "%pip install \"psycopg[binary]\" pgvector pandarallel boto3 tqdm numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import boto3\n",
    "import json\n",
    "import psycopg\n",
    "from pgvector.psycopg import register_vector\n",
    "from pandarallel import pandarallel\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Initialize Bedrock client\n",
    "bedrock_runtime = boto3.client('bedrock-runtime')\n",
    "\n",
    "print(\"✅ Required libraries setup complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aurora PostgreSQL Database Setup\n",
    "\n",
    "Set up PostgreSQL with the pgvector extension and create our product catalog table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get database credentials from Secrets Manager\n",
    "client = boto3.client('secretsmanager')\n",
    "response = client.get_secret_value(SecretId='apg-pgvector-secret-RIV')\n",
    "database_secrets = json.loads(response['SecretString'])\n",
    "\n",
    "# Set up database connection parameters\n",
    "dbhost = database_secrets['host']\n",
    "dbport = database_secrets['port']\n",
    "dbuser = database_secrets['username']\n",
    "dbpass = database_secrets['password']\n",
    "\n",
    "def setup_database():\n",
    "    \"\"\"Set up database schema and tables\"\"\"\n",
    "    conn = psycopg.connect(\n",
    "        host=dbhost,\n",
    "        port=dbport,\n",
    "        user=dbuser,\n",
    "        password=dbpass,\n",
    "        autocommit=True\n",
    "    )\n",
    "\n",
    "    # Enable vector extension\n",
    "    conn.execute(\"CREATE EXTENSION IF NOT EXISTS vector;\")\n",
    "    register_vector(conn)\n",
    "\n",
    "    # Create schema\n",
    "    conn.execute(\"CREATE SCHEMA IF NOT EXISTS bedrock_integration;\")\n",
    "    \n",
    "    # Drop existing table if needed\n",
    "    conn.execute(\"DROP TABLE IF EXISTS bedrock_integration.product_catalog;\")\n",
    "\n",
    "    # Create products table\n",
    "    conn.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS bedrock_integration.product_catalog (\n",
    "        \\\"productId\\\" VARCHAR(255) PRIMARY KEY,\n",
    "        product_description TEXT,\n",
    "        imgUrl TEXT,\n",
    "        productURL TEXT,\n",
    "        stars NUMERIC,\n",
    "        reviews INT,\n",
    "        price NUMERIC,\n",
    "        category_id INT,\n",
    "        isBestSeller BOOLEAN,\n",
    "        boughtInLastMonth INT,\n",
    "        category_name VARCHAR(255),\n",
    "        quantity INT,\n",
    "        embedding vector(1024)\n",
    "    );\n",
    "    \"\"\")\n",
    "\n",
    "    # Create HNSW index\n",
    "    conn.execute(\"\"\"\n",
    "    CREATE INDEX IF NOT EXISTS product_catalog_embedding_idx \n",
    "    ON bedrock_integration.product_catalog \n",
    "    USING hnsw (embedding vector_cosine_ops);\n",
    "    \"\"\")\n",
    "        \n",
    "    print(f\"Connection info: host={dbhost}, port={dbport}, user={dbuser}\")\n",
    "    print(\"✅ Database setup complete\")\n",
    "    conn.close()\n",
    "\n",
    "setup_database()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Product Data\n",
    "\n",
    "Load and preprocess the product catalog data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load product data\n",
    "print(\"Loading product data...\")\n",
    "df = pd.read_csv('../datasets/product_catalog.csv')\n",
    "\n",
    "# Clean up missing values\n",
    "df = df.dropna(subset=['product_description'])\n",
    "df = df.fillna({\n",
    "    'stars': 0,\n",
    "    'reviews': 0,\n",
    "    'price': 0,\n",
    "    'category_id': 0,\n",
    "    'isBestSeller': False,\n",
    "    'boughtInLastMonth': 0,\n",
    "    'category_name': 'Unknown',\n",
    "    'quantity': 0\n",
    "})\n",
    "\n",
    "print(f\"Loaded {len(df)} products\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Embeddings\n",
    "\n",
    "Generate embeddings using Amazon Bedrock's Titan model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embedding(text):\n",
    "    \"\"\"Generate embedding for a single text using Amazon Titan Text v2\"\"\"\n",
    "    try:\n",
    "        payload = json.dumps({'inputText': text})\n",
    "        response = bedrock_runtime.invoke_model(\n",
    "            body=payload,\n",
    "            modelId='amazon.titan-embed-text-v2:0',\n",
    "            accept=\"application/json\",\n",
    "            contentType=\"application/json\"\n",
    "        )\n",
    "        response_body = json.loads(response.get(\"body\").read())\n",
    "        return response_body.get(\"embedding\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating embedding: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Initialize parallel processing\n",
    "print(\"\\nGenerating embeddings for product descriptions...\")\n",
    "pandarallel.initialize(progress_bar=True, nb_workers=8)\n",
    "\n",
    "# Generate embeddings\n",
    "df['embedding'] = df['product_description'].parallel_apply(generate_embedding)\n",
    "\n",
    "print(\"\\nCompleted embedding generation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store in Database\n",
    "\n",
    "Store the products and their embeddings in PostgreSQL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_products():\n",
    "    \"\"\"Store products in database\"\"\"\n",
    "    conn = psycopg.connect(\n",
    "        host=dbhost,\n",
    "        port=dbport,\n",
    "        user=dbuser,\n",
    "        password=dbpass,\n",
    "        autocommit=True\n",
    "    )\n",
    "    \n",
    "    print(\"Storing products in database...\")\n",
    "    try:\n",
    "        # Use executemany for better performance\n",
    "        data = [(\n",
    "            row['productId'],\n",
    "            row['product_description'],\n",
    "            row['imgUrl'],\n",
    "            row['productURL'],\n",
    "            row['stars'],\n",
    "            row['reviews'],\n",
    "            row['price'],\n",
    "            row['category_id'],\n",
    "            row['isBestSeller'],\n",
    "            row['boughtInLastMonth'],\n",
    "            row['category_name'],\n",
    "            row['quantity'],\n",
    "            row['embedding']\n",
    "        ) for _, row in df.iterrows()]\n",
    "        \n",
    "        with conn.cursor() as cur:\n",
    "            cur.executemany(\"\"\"\n",
    "            INSERT INTO bedrock_integration.product_catalog (\n",
    "                \"productId\", product_description, imgUrl, productURL,\n",
    "                stars, reviews, price, category_id, isBestSeller,\n",
    "                boughtInLastMonth, category_name, quantity, embedding\n",
    "            ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "            ON CONFLICT (\"productId\") DO UPDATE \n",
    "            SET \n",
    "                product_description = EXCLUDED.product_description,\n",
    "                imgUrl = EXCLUDED.imgUrl,\n",
    "                productURL = EXCLUDED.productURL,\n",
    "                stars = EXCLUDED.stars,\n",
    "                reviews = EXCLUDED.reviews,\n",
    "                price = EXCLUDED.price,\n",
    "                category_id = EXCLUDED.category_id,\n",
    "                isBestSeller = EXCLUDED.isBestSeller,\n",
    "                boughtInLastMonth = EXCLUDED.boughtInLastMonth,\n",
    "                category_name = EXCLUDED.category_name,\n",
    "                quantity = EXCLUDED.quantity,\n",
    "                embedding = EXCLUDED.embedding;\n",
    "            \"\"\", data)\n",
    "            \n",
    "        print(\"✅ Products stored in database\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error storing products: {str(e)}\")\n",
    "        raise\n",
    "    finally:\n",
    "        conn.close()\n",
    "\n",
    "# Load data with embeddings into the table\n",
    "store_products()\n",
    "print(\"\\n✅ Part 1 Complete: Setup and data loading finished!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
